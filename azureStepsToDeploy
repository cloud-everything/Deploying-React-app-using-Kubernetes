#=====start Docker desktop
#=====create a repo in azure console
#=====login to Azure in cli
az login
az acr login --name gratitudeRegistry


#=====push image to Azure
docker build -t gratitude_app:latest .
docker tag gratitude_app gratituderegistry.azurecr.io/gratituderegistry/image1
docker push gratituderegistry.azurecr.io/gratituderegistry/image1

#======connect to Azure kuberentes service via cloud shell
az account set --subscription 78feeasd73-a3bc-asdbdb-89c4-dabasdf2812b #Set the cluster subscription
az aks get-credentials --resource-group kubernetes-deployment --name gratitudeCluster --overwrite-existing #Download cluster credentials

#=====create a kubernetes cluster in azure console and switch to that namespace
kubectl config get-contexts #check all the clusters
kubectl config current-context #check the current cluster you are using
kubectl create namespace vishal
kubectl config set-context --current --namespace=vishal
kubectl get deployments --all-namespaces=true
kubectl get deployments --namespace <namespace-name>
kubectl describe deployment <deployment-name> --namespace <namespace-name>
kubectl exec -it gratitude-kube-6bcdc4d55f-5bclz -- bin/sh


#=====connect akscluster to containerregistry
az aks update --resource-group <your-resource-group> --name <your-aks-cluster> --attach-acr <your-acr-name>
kubectl apply -f azure-deploy.yml


#========launch a kubernetes Load balancer service and portforwarding to check if the deployments are successful
kubectl apply -f azure-service-ClusterIp.yml #use the Ip address to connect to the app on port 80


#================================================================
#================================================================
#================================================================
#================================================================
#==========1)launch a Load Balancer service and check to see if you are able to connect via external Ip address
kubectl apply -f azure-LoadBalancer-service.yml #use the ExternalIP


#======================================OR===================================


#==========2)launch a ClusterIp service and connect to kind Ingress to provide a external IO
#You need to have an Ingress controller (like NGINX) running in your cluster for the Ingress resource to work
# . Without an Ingress controller,  the Ingress resource won't be able to route traffic.

#===========================================================================================================
#https://stackoverflow.com/questions/59844622/ingress-configuration-for-k8s-in-different-namespaces
#https://kubernetes.github.io/ingress-nginx/deploy/#quick-start
#==============================================test with ingress demo===================================================
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.11.2/deploy/static/provider/cloud/deploy.yaml
kubectl get pods --namespace=ingress-nginx

#or can use helm but it is not working for some reason
helm upgrade --install ingress-nginx ingress-nginx \
  --repo https://kubernetes.github.io/ingress-nginx \
  --namespace ingress-nginx --create-namespace
kubectl get pods --namespace=ingress-nginx


#==============to check if ingress is wokring========================
kubectl create ingress demo-localhost --class=nginx \
  --rule="demo.localdev.me/*=demo:80"
#edit the ingress and remove the host part so that u can check access with ip address
kubectl port-forward --namespace=ingress-nginx service/ingress-nginx-controller 8080:80
#==============to check if ingress is wokring========================


#===============================================================create a ingress 
kubectl port-forward svc/frontendservice 80:80 #port forward to check
kubectl apply -f azure-Ingress.yml 
#make sure the class name is "ingressClassName: nginx" present in ingress spec
#check the host part and comment it if you are accessing only using ip address
#if host is present make sure the azure-Ingress file is correct
#using route53 or azure dns connect it to domain


 #=================================install certificates using cert-manager==========================================
 #go to certmanager documentation ===========https://cert-manager.io/docs/installation/kubectl/
 #go to ingress cert-manager documentation ===========https://cert-manager.io/docs/tutorials/acme/nginx-ingress/
 kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.15.3/cert-manager.yaml
 kubectl get pods --namespace cert-manager  #check for the pods 
 #make sure the secrets match and domain names are all same
 kubectl apply -f azure-ClusterIssuer.yml #deploy always in cert-manager namespace
 kubectl config set-context --current --namespace=ingress-nginx
 kubectl apply -f azure-Certificate.yml   #apply the certificate manifest in ingress namespace
 kubectl apply -f azure-Ingress.yml      #update the ingress with tls configuration and apply the manifest
 kubectl get certificate
 kubectl describe certificate letsencrypt-prod-key
 kubectl describe secret letsencrypt-prod-key






#===============================start to finish
az login
az acr login --name gratitudeRegistry
docker build -t gratitude_app:latest .
docker tag gratitude_app gratituderegistry.azurecr.io/gratituderegistry/image1
docker push gratituderegistry.azurecr.io/gratituderegistry/image1
az account set --subscription 78feeasd73-a3bc-asdbdb-89c4-dabasdf2812b #Set the cluster subscription
az aks get-credentials --resource-group kubernetes-deployment --name gratitudeCluster --overwrite-existing #Download cluster credentials
kubectl config get-contexts #check all the clusters
kubectl config current-context #check the current cluster you are using
kubectl create namespace vishal
kubectl config set-context --current --namespace=vishal
kubectl get deployments --all-namespaces=true
az aks update --resource-group <your-resource-group> --name <your-aks-cluster> --attach-acr <your-acr-name>
kubectl apply -f azure-deploy.yml
kubectl apply -f azure-service-ClusterIp.yml #use the Ip address to connect to the app on port 80
kubectl port-forward svc/frontendservice 80:80 #port forward to check
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.11.2/deploy/static/provider/cloud/deploy.yaml
kubectl get pods --namespace=ingress-nginx
kubectl apply -f azure-Ingress.yml 
kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.15.3/cert-manager.yaml
kubectl get pods --namespace cert-manager  #check for the pods 
kubectl apply -f azure-ClusterIssuer.yml #deploy always in cert-manager namespace
$ kubectl config set-context --current --namespace=ingress-nginx
kubectl apply -f azure-Certificate.yml   #apply the certificate manifest in ingress namespace
kubectl apply -f azure-Ingress.yml      #update the ingress with tls configuration and apply the manifest
kubectl get certificate #check in vishal namespace
kubectl describe certificate letsencrypt-prod-key
kubectl describe secret letsencrypt-prod-key